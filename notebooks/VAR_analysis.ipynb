{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Autoregression (VAR) Model for Economic and Financial Data Analysis\n",
    "This jupyter notebook provides an example of how to perform a Vector Autoregression (VAR) analysis on economic and financial data for a specific country. \n",
    "The data is sourced from two CSV files: 'world_bank_data.csv' and 'stock_data.csv' (downloaded from data.py file).\n",
    "\n",
    "### Merging datasets\n",
    "The 'world_bank_data.csv' file contains economic data from the World Bank, while 'stock_data.csv' contains financial data. The two datasets are merged based on the year and the country code.\n",
    "\n",
    "### The 'var_country' function\n",
    "The var_country function is the core of this script. It takes as input the merged data and a country code, and performs the following steps:\n",
    "\n",
    "- Data Preprocessing: The function first selects the 'value' and 'Close' columns from the data, which represent the economic and financial indicators, respectively. These columns are converted to numeric types and then standardized using the StandardScaler from sklearn.preprocessing.\n",
    "\n",
    "- Data Filtering: The function then filters the data for the specified country. If no data is available for the country, or if the data contains NaN or infinite values, the function returns an error message.\n",
    "\n",
    "- Stationarity Check: Before applying the VAR model, the function checks if the time series are stationary using the Augmented Dickey-Fuller test. If the p-value is greater than 0.05, the function suggests differencing the series and returns.\n",
    "\n",
    "- VAR Model: If the series are stationary, the function creates a VAR model using the VAR class from statsmodels.tsa.vector_ar.var_model. It fits the model with a maximum lag order of 12, selected based on the Akaike information criterion (AIC).\n",
    "\n",
    "- Results: Finally, the function prints the summary of the VAR model, which includes the coefficients, standard errors, t-statistics, and p-values for each predictor, as well as some overall model fit statistics.\n",
    "\n",
    "### Usage\n",
    "To use this script, simply replace 'DEU' with your desired country code in the last line of the script, and then run the script. The output will be the VAR model summary for the specified country.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas, a data manipulation and analysis library\n",
    "import pandas as pd\n",
    "\n",
    "# Import VAR model from statsmodels for time series analysis\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "\n",
    "# Import StandardScaler from sklearn for standardizing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import numpy for numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# Import adfuller (Augmented Dickey-Fuller) function from statsmodels.\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the World Bank data from a CSV file (downloaded from 'data.py' file) into a pandas DataFrame \n",
    "economic_data = pd.read_csv('world_bank_data.csv')\n",
    "\n",
    "# Load the stock data from a CSV file (downloaded from 'data.py' file) into a pandas DataFrame\n",
    "financial_data = pd.read_csv('stock_data.csv')\n",
    "\n",
    "# Convert the 'date' column in the economic_data DataFrame from string to datetime format, \n",
    "# then extract the year and replace the original 'date' column with the year\n",
    "economic_data['date'] = pd.to_datetime(economic_data['date'], format='%Y').dt.year\n",
    "\n",
    "# Convert the 'Date' column in the financial_data DataFrame from string to datetime format, \n",
    "# then extract the year and replace the original 'Date' column with the year\n",
    "financial_data['Date'] = pd.to_datetime(financial_data['Date']).dt.year\n",
    "\n",
    "# Merge the economic_data and financial_data DataFrames based on the year and country code.\n",
    "# The 'left_on' parameter specifies the columns to use from the left DataFrame (economic_data),\n",
    "# and the 'right_on' parameter specifies the columns to use from the right DataFrame (financial_data).\n",
    "merged_data = pd.merge(economic_data, financial_data, left_on=['date', 'countryiso3code'], right_on=['Date', 'Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform Vector Autoregression (VAR) on data for a specific country\n",
    "def var_country(data, country):\n",
    "    # Select the 'value' and 'Close' columns from the data, convert them to numeric types, \n",
    "    # and handle any errors during conversion by replacing the problematic values with NaN\n",
    "    data_for_regression = data[['value', 'Close']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Initialize a StandardScaler object to standardize the features to have mean=0 and variance=1\n",
    "    scaler = StandardScaler()\n",
    "    # Fit the scaler to the data and transform the data\n",
    "    # Then convert the result back to a DataFrame and keep the original column names\n",
    "    data_for_regression = pd.DataFrame(scaler.fit_transform(data_for_regression), columns=data_for_regression.columns)\n",
    "\n",
    "    # Print a message indicating the start of the analysis for the current country\n",
    "    print(f\"Analyzing data for {country}...\")\n",
    "    \n",
    "    # Filter the standardized data to include only the rows for the current country\n",
    "    data_country = data_for_regression[data['Country'] == country]\n",
    "\n",
    "    # If the filtered data is empty (i.e., there's no data for the current country), print a message and exit the function\n",
    "    if data_country.empty:\n",
    "        print(f\"No data available for {country}\")\n",
    "        return\n",
    "\n",
    "    # If the filtered data contains any NaN or infinite values, print a message and exit the function\n",
    "    if data_country.isna().any().any() or np.isinf(data_country).any().any():\n",
    "        print(f\"Data for {country} contains NaN or infinite values\")\n",
    "        return\n",
    "\n",
    "    # For each column in the filtered data, perform the Augmented Dickey-Fuller test to check for stationarity\n",
    "    # If the p-value is greater than 0.05, the series is likely non-stationary, so print a message and exit the function\n",
    "    for column in data_country.columns:\n",
    "        result = adfuller(data_country[column])\n",
    "        if result[1] > 0.05:\n",
    "            print(f\"The {column} series is not stationary. Consider differencing.\")\n",
    "            return\n",
    "\n",
    "    # Create a VAR model with the filtered data\n",
    "    model = VAR(data_country)\n",
    "\n",
    "    # Fit the model with a maximum lag order of 12, selected based on the Akaike information criterion (AIC)\n",
    "    results = model.fit(maxlags=12, ic='aic')\n",
    "\n",
    "    # Print the summary of the model fit, which includes the coefficients, standard errors, t-statistics, and p-values\n",
    "    print(results.summary())\n",
    "    print(\"\\n\\n\")  # Print two newline characters for better readability in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data for DEU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Summary of Regression Results   \n",
      "==================================\n",
      "Model:                         VAR\n",
      "Method:                        OLS\n",
      "Date:           Fri, 24, May, 2024\n",
      "Time:                     16:54:08\n",
      "--------------------------------------------------------------------\n",
      "No. of Equations:         2.00000    BIC:                   -8.89328\n",
      "Nobs:                     4017.00    HQIC:                  -8.94390\n",
      "Log likelihood:           6669.87    FPE:                0.000126955\n",
      "AIC:                     -8.97168    Det(Omega_mle):     0.000125389\n",
      "--------------------------------------------------------------------\n",
      "Results for equation value\n",
      "============================================================================\n",
      "               coefficient       std. error           t-stat            prob\n",
      "----------------------------------------------------------------------------\n",
      "const            -0.000194         0.000988           -0.197           0.844\n",
      "L1.value          0.997370         0.015834           62.991           0.000\n",
      "L1.Close         -0.000099         0.001266           -0.078           0.938\n",
      "L2.value          0.000001         0.022362            0.000           1.000\n",
      "L2.Close         -0.000100         0.001266           -0.079           0.937\n",
      "L3.value          0.000000         0.022362            0.000           1.000\n",
      "L3.Close         -0.000099         0.001266           -0.079           0.937\n",
      "L4.value         -0.000001         0.022362           -0.000           1.000\n",
      "L4.Close         -0.000097         0.001265           -0.077           0.939\n",
      "L5.value          0.000000         0.022362            0.000           1.000\n",
      "L5.Close         -0.000097         0.001265           -0.076           0.939\n",
      "L6.value          0.000000         0.022362            0.000           1.000\n",
      "L6.Close         -0.000097         0.001265           -0.077           0.939\n",
      "L7.value          0.000000         0.022362            0.000           1.000\n",
      "L7.Close         -0.000097         0.001265           -0.077           0.939\n",
      "L8.value          0.000000         0.022362            0.000           1.000\n",
      "L8.Close         -0.000097         0.001265           -0.077           0.939\n",
      "L9.value          0.000000         0.022362            0.000           1.000\n",
      "L9.Close         -0.000097         0.001265           -0.077           0.939\n",
      "L10.value         0.000001         0.022362            0.000           1.000\n",
      "L10.Close        -0.000098         0.001266           -0.078           0.938\n",
      "L11.value         0.000002         0.022362            0.000           1.000\n",
      "L11.Close        -0.000103         0.001266           -0.081           0.935\n",
      "L12.value        -0.002746         0.015835           -0.173           0.862\n",
      "L12.Close        -0.000100         0.001260           -0.079           0.937\n",
      "============================================================================\n",
      "\n",
      "Results for equation Close\n",
      "============================================================================\n",
      "               coefficient       std. error           t-stat            prob\n",
      "----------------------------------------------------------------------------\n",
      "const            -0.282688         0.012319          -22.948           0.000\n",
      "L1.value          0.011854         0.197418            0.060           0.952\n",
      "L1.Close         -0.072488         0.015789           -4.591           0.000\n",
      "L2.value         -0.000084         0.278821           -0.000           1.000\n",
      "L2.Close         -0.071331         0.015786           -4.519           0.000\n",
      "L3.value         -0.002901         0.278821           -0.010           0.992\n",
      "L3.Close         -0.066498         0.015781           -4.214           0.000\n",
      "L4.value          0.004773         0.278821            0.017           0.986\n",
      "L4.Close         -0.070560         0.015772           -4.474           0.000\n",
      "L5.value         -0.000869         0.278821           -0.003           0.998\n",
      "L5.Close         -0.074909         0.015767           -4.751           0.000\n",
      "L6.value          0.000005         0.278821            0.000           1.000\n",
      "L6.Close         -0.075033         0.015768           -4.759           0.000\n",
      "L7.value         -0.000538         0.278821           -0.002           0.998\n",
      "L7.Close         -0.074273         0.015768           -4.710           0.000\n",
      "L8.value          0.000355         0.278821            0.001           0.999\n",
      "L8.Close         -0.074701         0.015767           -4.738           0.000\n",
      "L9.value          0.001839         0.278821            0.007           0.995\n",
      "L9.Close         -0.074737         0.015772           -4.739           0.000\n",
      "L10.value         0.001049         0.278821            0.004           0.997\n",
      "L10.Close        -0.075842         0.015781           -4.806           0.000\n",
      "L11.value        -0.002626         0.278821           -0.009           0.992\n",
      "L11.Close        -0.074967         0.015786           -4.749           0.000\n",
      "L12.value        -0.010765         0.197434           -0.055           0.957\n",
      "L12.Close        -0.075019         0.015707           -4.776           0.000\n",
      "============================================================================\n",
      "\n",
      "Correlation matrix of residuals\n",
      "            value     Close\n",
      "value    1.000000  0.028339\n",
      "Close    0.028339  1.000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify the usage of the function var_country\n",
    "\n",
    "# Set the variable 'country' to the ISO code of the country you want to analyse.\n",
    "# In this case, 'DEU' stands for Germany. Replace 'DEU' with the code of your desired country.\n",
    "country = 'DEU'\n",
    "\n",
    "# Call the function var_country with the merged data and the specified country.\n",
    "# This will perform a Vector Autoregression (VAR) analysis on the data for the specified country.\n",
    "var_country(merged_data, country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "The Vector Autoregression (VAR) model was used to analyze the data for Germany (DEU). The model was fitted with a maximum lag order of 12, selected based on the Akaike information criterion (AIC).\n",
    "\n",
    "For the 'value' equation, the most significant predictor is the first lag of 'value' itself (L1.value), with a coefficient of 0.997370 and a p-value of 0.000, indicating strong evidence against the null hypothesis of the coefficient being zero. However, the coefficients for other lags of 'value' and 'Close' are not statistically significant (p-values are close to 1).\n",
    "\n",
    "For the 'Close' equation, the constant term and the lags of 'Close' are statistically significant (p-values close to 0). The coefficients for the lags of 'value' are not statistically significant.\n",
    "\n",
    "The correlation matrix of residuals shows a very low correlation between the residuals of 'value' and 'Close', suggesting that there is little linear relationship left in the residuals of the two series, which is a good sign for the model fit.\n",
    "\n",
    "### Note\n",
    "\n",
    "Please note that the interpretation of VAR model results can be complex and requires a good understanding of the subject matter and the data. The statistical significance of a variable does not necessarily imply its practical significance. It's also important to check other diagnostic measures and consider the model's assumptions and limitations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
